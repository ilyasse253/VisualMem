# VisualMem Configuration Example

# ============================================
# Module Selection
# ============================================
# Type of screen capturer (default: screenshot)
CAPTURER_TYPE=screenshot
# VLM backend type: 'vllm' (any OpenAI-compatible server is in type "vllm", no need to change)
# Storage implementation: 'lancedb' (vector)
STORAGE_TYPE=lancedb
# Storage mode: 'vector' (hybrid search enabled) 
STORAGE_MODE=vector

# ============================================
# Preprocessing Parameters
# ============================================
# Frame difference threshold (0.0-1.0). Only frames with diff > threshold are recorded.
SIMPLE_FILTER_DIFF_THRESHOLD=0.006

# ============================================
# VLM API Configuration
# ============================================
# API key for the VLM service (set to 'None' for self deployed vLLM without auth)
VLM_API_KEY=None
# VLM_API_KEY=<sk-your-key>
# Base URI for the VLM API
VLM_API_URI=http://localhost:8081
# VLM_API_URI=https://api.openai.com
# Model name or path to the model weights
VLM_API_MODEL=Qwen/Qwen3-VL-8B-Instruct
# VLM_API_MODEL=gpt5

# ============================================
# Query Enhancement (RAG Workflow)
# ============================================
# Enable LLM to rewrite/expand the user query for better retrieval
ENABLE_LLM_REWRITE=true
# Enable automatic time range extraction from natural language queries
ENABLE_TIME_FILTER=true
# Number of expanded queries to generate
QUERY_REWRITE_NUM=3
# Enable Hybrid Search (combining Dense/Vector search and Sparse/OCR search). If flase, Sparse search will be disabled
ENABLE_HYBRID=true
# Maximum number of images to load for each query(making it at mosty 3*2*20=120 with default settings)
MAX_IMAGES_TO_LOAD=20

# Optional: Independent API for Query Rewrite (defaults to VLM config if not set)
QUERY_REWRITE_API_KEY=<sk-your-key>
QUERY_REWRITE_BASE_URL=http://your-api-endpoint
QUERY_REWRITE_MODEL=gpt-5

# ============================================
# Reranker Configuration(only local)
# ============================================
# Enable a second-stage reranking using a multimodal modelï¼ˆif true, make sure you have at least 8GB GPU memory available)
ENABLE_RERANK=false
# Number of top results to keep after reranking
RERANK_TOP_K=20
# Model used for reranking (e.g. a smaller VLM)
RERANK_MODEL=Qwen/Qwen3-VL-2B-Instruct

# ============================================
# Storage Paths
# ============================================
# Root directory for all visual memory data
STORAGE_ROOT=./visualmem_storage
# Path to store captured screenshot images
IMAGE_STORAGE_PATH=./visualmem_storage/visualmem_image
# Path for the LanceDB vector database
LANCEDB_PATH=./visualmem_storage/visualmem_lancedb
# Path for the SQLite database (OCR and metadata)
OCR_DB_PATH=./visualmem_storage/visualmem_ocr.db
# Path for the OCR text vector index
TEXT_LANCEDB_PATH=./visualmem_storage/visualmem_textdb

# ============================================
# GUI & Remote Mode
# ============================================
# GUI_MODE: 
#   - 'local' : All processing (OCR, Embedding, Storage) happens on the local machine.
#   - 'remote': your local machine can't handle embedding& reranking, GUI only captures and sends frames to a remote backend server.
GUI_MODE=local
# URL of the remote backend server (only used if GUI_MODE=remote)
# GUI_REMOTE_BACKEND_URL=http://127.0.0.1:8080

# ============================================
# Benchmark Configuration (Optional)
# ============================================
# Name of the benchmark dataset to use
# BENCHMARK_NAME=VideoWatching
# Root path for benchmark images
BENCHMARK_IMAGE_ROOT=./visualmem_storage/visualmem_image/benchmarks
# Root path for benchmark databases
BENCHMARK_DB_ROOT=./visualmem_storage/dbs_benchmark

# ============================================
# Runtime Parameters
# ============================================
# Interval between screen captures in seconds
CAPTURE_INTERVAL_SECONDS=3
# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
